{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://deeplearningcourses.com/c/advanced-computer-vision\n",
    "# https://www.udemy.com/advanced-computer-vision\n",
    "from __future__ import print_function, division\n",
    "from builtins import range, input\n",
    "# Note: you may need to update your version of future\n",
    "# sudo pip install -U future\n",
    "\n",
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "# re-size all the images to this\n",
    "IMAGE_SIZE = [100, 100] # feel free to change depending on dataset\n",
    "\n",
    "# training config:\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "# https://www.kaggle.com/paultimothymooney/blood-cells\n",
    "# train_path = '../large_files/blood_cell_images/TRAIN'\n",
    "# valid_path = '../large_files/blood_cell_images/TEST'\n",
    "\n",
    "# https://www.kaggle.com/moltean/fruits\n",
    "train_path = '../large_files/fruits-360/Training'\n",
    "valid_path = '../large_files/fruits-360/Validation'\n",
    "# train_path = '../large_files/fruits-360-small/Training'\n",
    "# valid_path = '../large_files/fruits-360-small/Validation'\n",
    "\n",
    "# useful for getting number of files\n",
    "image_files = glob(train_path + '/*/*.jp*g')\n",
    "valid_image_files = glob(valid_path + '/*/*.jp*g')\n",
    "\n",
    "# useful for getting number of classes\n",
    "folders = glob(train_path + '/*')\n",
    "\n",
    "\n",
    "# look at an image for fun\n",
    "plt.imshow(image.img_to_array(image.load_img(np.random.choice(image_files))).astype('uint8'))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# add preprocessing layer to the front of VGG\n",
    "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "# don't train existing weights\n",
    "for layer in vgg.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "# our layers - you can add more if you want\n",
    "x = Flatten()(vgg.output)\n",
    "# x = Dense(1000, activation='relu')(x)\n",
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "\n",
    "\n",
    "# create a model object\n",
    "model = Model(inputs=vgg.input, outputs=prediction)\n",
    "\n",
    "# view the structure of the model\n",
    "model.summary()\n",
    "\n",
    "# tell the model what cost and optimization method to use\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='rmsprop',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "# create an instance of ImageDataGenerator\n",
    "gen = ImageDataGenerator(\n",
    "  rotation_range=20,\n",
    "  width_shift_range=0.1,\n",
    "  height_shift_range=0.1,\n",
    "  shear_range=0.1,\n",
    "  zoom_range=0.2,\n",
    "  horizontal_flip=True,\n",
    "  vertical_flip=True,\n",
    "  preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "\n",
    "# test generator to see how it works and some other useful things\n",
    "\n",
    "# get label mapping for confusion matrix plot later\n",
    "test_gen = gen.flow_from_directory(valid_path, target_size=IMAGE_SIZE)\n",
    "print(test_gen.class_indices)\n",
    "labels = [None] * len(test_gen.class_indices)\n",
    "for k, v in test_gen.class_indices.items():\n",
    "  labels[v] = k\n",
    "\n",
    "# should be a strangely colored image (due to VGG weights being BGR)\n",
    "for x, y in test_gen:\n",
    "  print(\"min:\", x[0].min(), \"max:\", x[0].max())\n",
    "  plt.title(labels[np.argmax(y[0])])\n",
    "  plt.imshow(x[0])\n",
    "  plt.show()\n",
    "  break\n",
    "\n",
    "\n",
    "# create generators\n",
    "train_generator = gen.flow_from_directory(\n",
    "  train_path,\n",
    "  target_size=IMAGE_SIZE,\n",
    "  shuffle=True,\n",
    "  batch_size=batch_size,\n",
    ")\n",
    "valid_generator = gen.flow_from_directory(\n",
    "  valid_path,\n",
    "  target_size=IMAGE_SIZE,\n",
    "  shuffle=True,\n",
    "  batch_size=batch_size,\n",
    ")\n",
    "\n",
    "\n",
    "# fit the model\n",
    "r = model.fit_generator(\n",
    "  train_generator,\n",
    "  validation_data=valid_generator,\n",
    "  epochs=epochs,\n",
    "  steps_per_epoch=len(image_files) // batch_size,\n",
    "  validation_steps=len(valid_image_files) // batch_size,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def get_confusion_matrix(data_path, N):\n",
    "  # we need to see the data in the same order\n",
    "  # for both predictions and targets\n",
    "  print(\"Generating confusion matrix\", N)\n",
    "  predictions = []\n",
    "  targets = []\n",
    "  i = 0\n",
    "  for x, y in gen.flow_from_directory(data_path, target_size=IMAGE_SIZE, shuffle=False, batch_size=batch_size * 2):\n",
    "    i += 1\n",
    "    if i % 50 == 0:\n",
    "      print(i)\n",
    "    p = model.predict(x)\n",
    "    p = np.argmax(p, axis=1)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    predictions = np.concatenate((predictions, p))\n",
    "    targets = np.concatenate((targets, y))\n",
    "    if len(targets) >= N:\n",
    "      break\n",
    "\n",
    "  cm = confusion_matrix(targets, predictions)\n",
    "  return cm\n",
    "\n",
    "\n",
    "cm = get_confusion_matrix(train_path, len(image_files))\n",
    "print(cm)\n",
    "valid_cm = get_confusion_matrix(valid_path, len(valid_image_files))\n",
    "print(valid_cm)\n",
    "\n",
    "\n",
    "# plot some data\n",
    "\n",
    "# loss\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# accuracies\n",
    "plt.plot(r.history['accuracy'], label='train acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "from util import plot_confusion_matrix\n",
    "plot_confusion_matrix(cm, labels, title='Train confusion matrix')\n",
    "plot_confusion_matrix(valid_cm, labels, title='Validation confusion matrix')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2.4_PY3.7",
   "language": "python",
   "name": "tf2.4_py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
